{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92511c0e-d6a5-40d2-b21d-200c59eaf9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ds_config(cfg):\n",
    "    \"\"\"\n",
    "    Generate a DeepSpeed config dict from the training config.\n",
    "    \n",
    "    Args:\n",
    "        cfg (dict): Your full config dictionary containing \"training\", \"model\", etc.\n",
    "        \n",
    "    Returns:\n",
    "        dict: DeepSpeed config dictionary ready for deepspeed.initialize()\n",
    "    \"\"\"\n",
    "    training = cfg[\"training\"]\n",
    "    \n",
    "    # Compute train_batch_size as micro_batch_size * gradient_accumulation_steps\n",
    "    train_batch_size = training.get(\"micro_batch_size\", training.get(\"batch_size\", 16)) \\\n",
    "                       * training.get(\"gradient_accumulation_steps\", 1)\n",
    "    \n",
    "    # Determine if fp16 is enabled\n",
    "    fp16_enabled = training.get(\"fp16\", False)\n",
    "    \n",
    "    # Select scheduler type\n",
    "    lr_scheduler = training.get(\"lr_scheduler\", \"warmup\").lower()\n",
    "    if lr_scheduler == \"cosine\":\n",
    "        scheduler_config = {\n",
    "            \"type\": \"CosineAnnealing\",\n",
    "            \"params\": {\n",
    "                \"warmup_min_lr\": 0,\n",
    "                \"warmup_max_lr\": training.get(\"learning_rate\", 3e-4),\n",
    "                \"warmup_num_steps\": training.get(\"warmup\", 2000)\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        scheduler_config = {\n",
    "            \"type\": \"WarmupLR\",\n",
    "            \"params\": {\n",
    "                \"warmup_min_lr\": 0,\n",
    "                \"warmup_max_lr\": training.get(\"learning_rate\", 3e-4),\n",
    "                \"warmup_num_steps\": training.get(\"warmup\", 2000)\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Build the DeepSpeed config\n",
    "    ds_config_dict = {\n",
    "        \"train_batch_size\": train_batch_size,\n",
    "        \"train_micro_batch_size_per_gpu\": training.get(\"micro_batch_size\", 16),\n",
    "        \"gradient_accumulation_steps\": training.get(\"gradient_accumulation_steps\", 1),\n",
    "        \"optimizer\": {\n",
    "            \"type\": training.get(\"optimizer_type\", \"AdamW\"),\n",
    "            \"params\": {\n",
    "                \"lr\": training.get(\"learning_rate\", 3e-4),\n",
    "                \"betas\": training.get(\"betas\", [0.9, 0.95]),\n",
    "                \"weight_decay\": training.get(\"weight_decay\", 0.0)\n",
    "            }\n",
    "        },\n",
    "        \"fp16\": {\"enabled\": fp16_enabled},\n",
    "        \"scheduler\": scheduler_config,\n",
    "        \"gradient_clipping\": training.get(\"max_grad_norm\", 1.0),\n",
    "        \"steps_per_print\": 2000,\n",
    "        \"zero_optimization\": False  # can set True if using ZeRO stage\n",
    "    }\n",
    "    \n",
    "    return ds_config_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb012be4-76cb-4591-b3ad-af64a15af2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "  \"model\": {\n",
    "    \"n_layer\": 24,\n",
    "    \"n_head\": 16,\n",
    "    \"d_model\": 2048,\n",
    "    \"d_ff\": 8192,\n",
    "    \"max_seq_len\": 1024,\n",
    "    \"dropout\": 0.1,\n",
    "  },\n",
    "  \"training\": {\n",
    "    \"batch_size\": 16,\n",
    "    \"micro_batch_size\": 16,\n",
    "    \"gradient_accumulation_steps\": 1,\n",
    "    \"n_epochs\": 1,\n",
    "    \"total_tokens_target\": 40000000000,\n",
    "    \"learning_rate\": 3e-4,\n",
    "    \"betas\": [0.9, 0.95],\n",
    "    \"weight_decay\": 0.1,\n",
    "    \"warmup\": 2000,\n",
    "    \"lr_scheduler\": \"cosine\",\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"seed\": 1,\n",
    "    \"fp16\": True,\n",
    "    \"save_dir\": \"saved_model\",\n",
    "    \"save_every_steps\": 100000,\n",
    "    \"optimizer_type\": \"AdamW\"\n",
    "  },\n",
    "  \"data\": {\n",
    "    \"datasets\": [\n",
    "      {\"name\": \"wikitext\", \"config\": \"wikitext-103-raw-v1\", \"weight\": 0.01, \"split\": \"train\"},\n",
    "      {\"name\": \"allenai/c4\", \"config\": \"en\", \"weight\": 0.79, \"split\": \"train\"},\n",
    "      {\"name\": \"multilingual-mi-llm/pile\", \"split\": \"train\", \"weight\": 0.2, \"filter_name\": [\"meta\",\"pile_set_name\"], \"filter_value\": \"ArXiv\"}\n",
    "    ],\n",
    "    \"english_only\": True,\n",
    "    \"min_length\": 20,\n",
    "    \"shuffle_buffer\": 10000\n",
    "  },\n",
    "  \"model_name\": \"llm_expert_3B\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7075eba-0483-4145-b096-9854fde196a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_batch_size': 16,\n",
       " 'train_micro_batch_size_per_gpu': 16,\n",
       " 'gradient_accumulation_steps': 1,\n",
       " 'optimizer': {'type': 'AdamW',\n",
       "  'params': {'lr': 0.0003, 'betas': [0.9, 0.95], 'weight_decay': 0.1}},\n",
       " 'fp16': {'enabled': True},\n",
       " 'scheduler': {'type': 'CosineAnnealing',\n",
       "  'params': {'warmup_min_lr': 0,\n",
       "   'warmup_max_lr': 0.0003,\n",
       "   'warmup_num_steps': 2000}},\n",
       " 'gradient_clipping': 1.0,\n",
       " 'steps_per_print': 2000,\n",
       " 'zero_optimization': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ds_config(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b123f356-b084-4f43-92fd-757162d114c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
