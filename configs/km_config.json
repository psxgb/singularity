{
  "model": {
    "n_layer": 3,
    "n_head": 8,
    "d_model": 256,
    "d_ff": 256,
    "max_seq_len": 256,
    "dropout": 0.1,
    "tie_word_embeddings": true,
    "use_rope": true
  },
  "training": {
    "train_batch_size": 16,
    "total_tokens_target": 40000000000,
    "learning_rate": 3e-4,
    "betas": [0.9, 0.95],
    "weight_decay": 0.1,
    "warmup": 2000,
    "max_grad_norm": 1.0,
    "seed": 1,
    "fp16": true,
    "save_dir": "saved_model",
    "save_every_steps": 100000,
    "optimizer_type": "AdamW"
  },
  "data": {
    "datasets": [
      {"name": "wikitext", "config": "wikitext-103-raw-v1", "weight": 0.01, "split": "train"},
      {"name": "allenai/c4", "config": "en", "weight": 0.79, "split": "train"},
      {"name": "multilingual-mi-llm/pile", "split": "train", "weight": 0.2, "filter_name": ["meta","pile_set_name"], "filter_value": "ArXiv"}
    ],
    "english_only": true,
    "min_length": 20
  },
  "model_name": "llm_expert_3B"
}